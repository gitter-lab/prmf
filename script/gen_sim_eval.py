#!/usr/bin/env python
import sys, argparse
import os, os.path
import numpy as np
import pandas as pd
import networkx as nx
import factorlib as fl
import re

# TODO 
# used to represent the ground truth pathways which are assumed to be the first K_LATENT pathways in the pathways file 
K_LATENT = 30
PATHWAY_INT_REGEXP = re.compile('pathway(\d+)')

def main():
  parser = argparse.ArgumentParser(description="""
Script to evaluate matrix factorization methods where data is generated by nmf_pathway_sim_gen.py
Evaluation is reported as a box and whisker plot for each method where we are measuring the 
number of ground truth pathways that each method recovers in each simulated run 
""")
  parser.add_argument("--indir", help="Argument used as outdir to gen_sim_pipeline.py")
  parser.add_argument("--outdir", help="Directory to write results including a box and whisker plot for all the methods evaluated")
  args = parser.parse_args()

  sim_dirs = os.listdir(args.indir)
  pathways_files = []
  nmf_gene_by_latent_files = []
  prmf_obj_files = []
  plier_pathway_by_latent_files = []
  for sim_dir in sim_dirs:
    pathways_files.append(os.path.join(sim_dir, 'pathways_file.txt'))
    nmf_gene_by_latent_files.append(os.path.join(sim_dir, 'nmf', 'V.csv'))
    prmf_obj_files.append(os.path.join(sim_dir, 'prmf', 'obj.txt'))
    plier_pathway_by_latent_files.append(os.path.join(sim_dir, 'plier', 'U.csv'))

  nmf_vals = eval_nmf_runs(nmf_gene_by_latent_files)
  prmf_vals = eval_prmf_runs()
  plier_vals = eval_plier_runs()

def eval_nmf_runs(pathways_files, nmf_gene_by_latent_files):
  vals = np.zeros((len(nmf_gene_by_latent_files),))
  if len(pathways_files) != len(nmf_gene_by_latent_files):
    raise Exception("len(pathways_files) = {} != {} = len(nmf_gene_by_latent_files)".format(len(pathways_files), len(nmf_gene_by_latent_files)))

  for i in range(len(pathway_files)):
    pathways_file = pathway_files[i]
    pathways = parse_pathways(pathways_file)

    nmf_gene_by_latent_file = nmf_gene_by_latent_files[i]
    nmf_gene_by_latent_df = pd.read_csv(nmf_gene_by_latent_file, index_col=0)
    
    pathway_latent_scores = np.zeros((len(pathways), K_LATENT))
    for j in range(len(pathways)): 
      pathway_names = list(map(lambda x: x[1]['name'], pathways[i].nodes(data=True))) 
      pathway_names_set = set(pathway_names) 
      all_names = set(nmf_gene_by_latent_df.index) 
      non_pathway_names = all_names - pathway_names_set 
      for k in range(K_LATENT): 
        pathway_latent_scores[j,k] = np.mean(nmf_gene_by_latent_df.loc[pathway_names,"LV{}".format(k)]) 
    latent_to_pathway = np.argmax(pathway_latent_scores, axis=0)
    vals[i] = np.sum(latent_to_pathway < K_LATENT)

  return vals

def eval_prmf_runs(pathways_files, prmf_obj_files):
  if len(pathways_files) != len(prmf_obj_files):
    raise Exception("len(pathways_files) = {} != {} = len(prmf_obj_files)".format(len(pathways_files), len(prmf_obj_files)))

  vals = np.zeros((len(prmf_obj_files),))
  for i in range(len(prmf_obj_files)):
    prmf_obj_file = prmf_obj_files[i]
    latent_to_pathway = fl.parse_pathway_obj(prmf_obj_file)
    for k, v in latent_to_pathway.items():
      pathay_int = parse_pathway_int(v)
      if pathway_int < K_LATENT:
        vals[i] += 1
  return vals

def eval_plier_runs(pathways_files, plier_pathway_by_latent_files):
  if len(pathways_files) != len(plier_pathway_by_latent_files):
    raise Exception("len(pathways_files) = {} != {} = len(plier_pathway_by_latent_files)".format(len(pathways_files), len(plier_pathway_by_latent_files)))

  vals = np.zeros((len(plier_pathway_by_latent_files),))
  for i in range(len(plier_pathway_by_latent_files)):
    plier_pathway_by_latent_file = plier_pathway_by_latent_files[i]
    plier_pathway_by_latent_df = pd.read_csv(plier_pathway_by_latent_file, index_col=0)
    argmax_df = np.argmax(plier_pathway_by_latent_df, axis=0)
    # TODO check this logic especially, also need to update PLIER to correctly report the pathway names as row names in the U matrix
    for pathway_bn in argmax_df.index:
      pathway_int = parse_pathway_int(pathway_bn)
      if pathway_int < K_LATENT:
        vals[i] += 1
  return vals

def get_true_pathways(pathways_file):
  rv = []
  with open(pathways_file, 'r') as fh:
    i = 0
    for line in fh:
      line = line.rstrip()
      rv.append(line)
      i += 1
      if i >= 30:
        break
  return rv

def parse_pathways(pathways_file):
  rv = []
  with open(pathways_file, 'r') as fh:
    for line in fh:
      line = line.rstrip()
      G = nx.read_graphml(line)
      rv.append(G)
  return rv

def parse_pathway_int(pathway_fp):
  match_data = PATHWAY_INT_REGEXP.search(pathway_fp)
  # TODO currently just propagating the match error if it occurs
  # need to do something if match_data is None
  return int(match_data.group(1))

if __name__ == "__main__":
  main()
